
（Ch 3 好像要講一下為什麼不做連續特徵 \& 為什麼要以 phoneme 為客體了 T\_T） 
\section{動機簡介}  % \section{簡介}



由於 HuBERT 之後，unit 的使用很廣泛，因此為了研究 unit 本身為什麼會被如此適當的可以讓模型視為文字對語音資料進行訓練，我們先從離散表徵本身的特徵分析起。 

由于 HuBERT 模型在使用离散单元进行语音处理方面取得了显著成功，为了研究这些单元为什么能够如此有效地训练模型，我们从离散表征本身的特征分析起。探讨这些单元是否能够替代文字作为语音数据的表征，并分析其与语言学标签之间的关系。 


\section{相關研究}
近期已經有多項相關的研究，嘗試在 SSL 這麼厲害的表現之後找原因，因此有針對 unit 背後 repr 的特性進行分析的 work，例如 CITEUSPLEASE。 

\subsection{語音表徵的語音學分析}
在 HuBERT 出來之後，有一些研究像是 cite 等等，試圖探討對於語音表徵這樣語音模型的基礎進行各種從統計和語音學領域知識角度的分析，以期望能夠解釋為什麼模型可以擁有如此的表現。

此後，cite 等等作品則是從原先連續的表徵出發，開始往離散的量化向量，甚至是離散單元進行分析比對。雖然分析的切入角度可以相當多樣，例如 ABX、tsne 降維分群等等，但本次研究主要著重比對兩者之間在同一段語音序列上給予標籤的相關性，也就是以「偽標籤（pseudo-label）」的角度進行衡量。

\subsection{無文字（textless）語言模型}

這系列 textless 以 GSLM 為最主要代表作，旨在探討 unit 作為一種替代文字的方案。

本論文以 GSLM textless 採用的模型 units 為主要分析對象，企圖銜接兩者的脈絡，來佐證這些 unit 作為一種「類似或可替代文字的語音紀錄方式」在能夠發揮 LM 的特長背後，是否是基於符合語音學特徵帶來的，抑或有什麼其他特徵。



\subsubsection{相关研究}

近期有多项相关研究尝试在 SSL 表现优异之后探讨其原因，例如 Hsu 等人的研究。他们的研究表明，通过使用 k-means 聚类生成的隐藏单元作为预训练的目标标签，HuBERT 模型能够在低资源条件下取得卓越的语音识别性能。这一发现表明，pseudo-label 技术在自监督学习中起到了关键作用。

\paragraph{语音表征的语言学分析}

在 HuBERT 出现之后，一些研究试图从统计和语言学领域知识角度分析语音表征，例如 Wells 等人的研究。这些研究通过分析离散表征与语言学标记的对应关系，探讨模型为何能够如此有效地捕捉语音数据的结构和模式。常见的方法包括 ABX 测试、t-SNE 降维分群等。

\paragraph{无文字（Textless）语言模型}

本论文以 GSLM textless 采用的模型 units 为主要分析对象，企图探讨这些 unit 是否符合语言学特征，或者有其他特征。

 