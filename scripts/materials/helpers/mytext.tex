% !TeX root = ../../thesis.tex
\chapter{導論}
\section{研究動機}  % 為什麼

　　語言是人與人之間最主要的溝通方式，是我們對外界世界互動最主要的媒介。隨著時代的發展，在這個資訊爆炸的社會，人們接觸到語言、使用與互動的情形變得非常頻繁。然而，語言的多樣性在此卻成為一項阻礙不同人們交流的障礙，因此，發展語言科技為人們的互動提供協助，因而成為了一項不可避免的趨勢。藉助科技與知識的力量，人們可以透過不同語言的視角去獲取更多元的資訊，激發思考、開拓視野，因此諸如語音辨識、機器翻譯等等，一直都是人們熱衷於研究的議題。

    過往，為了達成此一遠大目標，機器學習工程師們與語言學家之間互相合作，期望藉由對領域知識的了解去建立模型，打造出創新的技術以應對語言的各種變化，來滿足人們溝通的需求。近年來，由於硬體平行運算技術的進步，深層學習（deep learning）快速崛起成為人工智慧的主流，有了此項機器學習的技術，模型的彈性能夠更好的萃取資料、更貼近的尋找資料背後的機制並進行預測，使得人們不再非得依賴大量費時費工的人類標註過程，進而使得利用大量語料庫發展語言技術，進一步推進語言科技發展成為可能。尤其在自監督學習（self-supervision）技術出現之後，深層學習模型可以依照人們給定的方向，更細緻的從大量未標注、相較容易取得的語音或文字的語料，找出其中的語音、語法及語義等等結構，形成帶有對人類語言有前所未見表現的基礎模型（foundation model），是這個領域的一大里程碑。尤其在以處理文字為主體的自然語言處理領域，甚至出現了幾乎使人類真偽難辨的生成式模型，改變了人們生活的方方面面。

    ……………………………………………………………………… \\
    ………………………………………………………………………………… \\
　　………………………………………………………………………

    然而相較於穩定、易於處理的文字文本，語音訊號的變化複雜萬千，蘊藏了大量如內容、韻律、語者等等不同層次的訊息，使得處理的難度劇增。更何況，目前世界上大約七千多種語言中，絕大多數仍然沒有成熟且普及的文字系統。

    （先從語音表徵開始）

    因此，除了發展文字的模型以外，語音處理的技術更是必不可少的。
而在語音處理這邊，近期藉由自監督學習，提出了許多語音這邊的基礎模型。
% 這部分跟前面重疊到了
另外，由於語音的獨特性質的關係，因此，我們需要處理掉語音中更多不同的資訊 在這樣的情境之下 向量的量化（quantization）可以起到很好的作用 將 將內容這樣跟語者、韻律等等與內容比較無關的資訊很好的進行一定程度的過濾。 由此量化過程，語音訊號的表征本身就形成了類似於文字的 序列。 就此激發了。 聲音單位尋找等。 系列的靈感。 另外 也導致。 無文字相關的 研究開始進行。 例如。 Hubert 等模型能夠更好的。 抓到語音中的類似峰嶺的單位。 

    因此在語音處理界，「無文字（textless）」的發展是相當吸引人的。

    （加上語言公平性問題？）

    近期由於 HuBERT 等等起來的 GSLM 等架構，已經在一定程度上做到完全不依賴文字轉寫、單純在大量的語音語料之上建立一定程度上媲美於「大型語言模型」的成果，甚至達成了閩南語和英語的互相對譯。此一里程碑大力的推動了語言科技的進展，有望推動藉助科技達成的降低語言障礙。

    ………………………………………………………………………………

    
    
   不過，即便語音的技術已經相當成熟，在追求模型表現的同時，語音與語言的技術開始與過往的人類對於語言學、語音的理解逐漸產生脫節。似乎在為了讓機器可以擁有良好表現的同時，理解模型如何運作似乎是被犧牲的必然。但人們在追求更好的模型表現的同時，有一群人開始注意到語音處理模型是否有可能抓取到人類語音中特有的、區別於一般音訊的特徵，並嘗試使用過往用來研究、歸類人類語音的方式，結合機器學習與統計學去解釋為什麼，並期求可以比較甚至改善機器模型在進行語音處理時的表現，不僅僅只是使用資料集本身的分數，而有更多更多元、更穩健的衡量標準。由於離散表徵在當今語音模型與語音處理技術已經愈來愈具備重要性，因此探討與分析為什麼語音離散表徵可以幫助下游任務的背後成因是相當重要的研究方向，其中一個驗證離散表徵能夠幫助模型處理語音訊號的方式，便是驗證其與音位（phoneme）之間的對應關係。

    我們想要知道的是，在離散單元推動語音處理發展的同時，它究竟與人類書寫和使用的文字還有多遠的差異，以及在使用上是否能夠達成如同文字的效果，仍舊是領域中尚待探討的議題。所以我們先看看，他是不是起碼符合語音學上，作為「捕捉語音內容」的基本特徵。

    % （加上跟 LLM 的關係嗎？）
    我們希望當今天語音表真。 離散表征本身 能夠更接近語音學特征的話。 我們能夠借由這個作為類似文字的。 基礎網上學習大型語言模型所需要的資訊 比起直接在連續表征上面處理更加復雜的語音資訊我們可以讓模型更聚焦於內容本身 

    也就是 Phonology 去討論這件事，看它跟聲學特徵跟語音到底有多像，從這個方向我們可以進而去改善說，也許我們可以去用不同的方式使用 Unit ，來進一步推進讓我們的 Unwritten Language 這些技術，能夠更好的跟，就是等於說進而發揮類似文字的效果，然後同時也能促進我們去知道，機器是怎麼樣去理解這些語音訊號，它可能看的是哪些部分。

    ……………………………………………………………………… \\
    ………………………………………………………………………………… \\
　　………………………………………………………………………


\section{研究方向}  % 做什麼

%%%     於是我們對這些離散單元進行了單一的分析
%%%     另外，因為人類的音素往往是超過一個音框的單位
%%%     因此推測離散單元單一本身會抓取到的是更加細緻的特徵
%%% 
%%%     那為了找出更加符合人類文字認知的表示符號
%%%     因此我們採用文字那邊常用的分詞器
%%%     // 可能要紀錄 rate 來證明這件事了
%%%     嘗試看看可否找出更接近人們認知信息率的符號，以其這種機器抓出
%%% 來的 fine structure 可以更往人類的文字靠近
%%% 
%%%     具體方法是，針對這些抓出來的 unit 跟 piece, 我們去算 purtiy,
%%% pmni, segmentation 這些指標，看看他們是不是真的跟人類 top down
%%% 標註出來的的 phoneme label 有統計上的一致性。
%%% 
%%%     最後我們嘗試做在 PR 或 ASR 上，驗證這個一致性不是僅僅在統計數
%%% 據上顯現，也是可以在應用上得到幫助的。

　　在近年，已經有不少相關的研究開始嘗試往將離散單元（discrete unit）作為除了連續表徵（continuous representation）以外，可以編碼（encode）語音訊號的另外一種方式。離散表徵（discrete representation）跟連續表徵相比，具有資訊更濃縮（位元率（bit rate）更低）因此更好儲存、處理與傳輸，以及形式上更像文字的特性。

    儘管離散表徵在語音社群（community）中常被當成一種類似文字的存在，另外有一些文獻則是將其當成連續表徵的精簡表示法。

    然而

    因此，我們藉由分析各種離散單元和人類理解語音最直接的處理層次：音位（phoneme）之間的關係，並將兩者進行各種統計上的序列比較，可以作為訓練大型語音基石模型（foundation model）的分詞（tokenization）基礎，選定最適合的表徵最為系統的輸入符記（token）。

    例如 \cite{wu2023wav2seq} 等作品便是首先嘗試將離散單元進行 tokenization 後做進一步處理的，其後的

    % 　　在過往他們做 speech discrete units 的這些representation的當中，Purity的基本指標就是去elaborate說他們今天discover出來的那個unit本身，與 phoneme 之間的一致性有多高，所以一定會說Purity以及PNMI這兩個指標，然後呢，他們我們就先對基本的一些unit，尤其是在 textless 這個里程碑上面去做這些分析，然後接下來我們會嘗試想說就是有一個假設是，基於有文獻以及從語言學上面看到的一些現象，我們可以發掘，比如說，或許，或許，Unit itself does not represent the phonological structure at all，only，就是你會需要一個Sequence，也許Deduplication本身很重要，所以我們會比較說，如果借用文字那邊 BPE，就有點像從Button-up裡面去，從更fine structure的信號角度去，組成一個人類從Top-down認知的 phoneme 這個角色之間，我們可不可以借用文字的 tokenization 演算法，去達成discovery這些東西的目的，然後一樣去分析這兩個，他們的那些資訊的角度，就是把這個單位當成新的Acoustic unit，就是Acoustic unit discovery他們在做的事情，那這就是一個簡單的分析的方式，最後我們會把它測試在 phoneme recognition，畢竟我們discovery如果是 phoneme ，它應該有一個準確率，但在應用的角度上我們會做Speech recognition這樣子，因為這就能直接反應到，它有沒有抽到裡面的content


\section{主要貢獻}  % 有什麼

　　結果我們發現，藉由觀察這些 unit 並嘗試藉由分詞演算法找出更 high-level 的單位之後，我們觀察到這些機器學習 figure out 的「偽標記」一定程度上的符合了人類音素的特性，因此可以當成某種類似拼音文字的存在。當然這跟人類真正使用的拼音文字仍有距離，
% // 難道可以探討 text 是不是一種 speech tokenization 過程嗎？
因此雖然無法直接當成 exact 的文字使用，一些人類的標注還是需要的，不過透過 ML 我們已經可以盡量更有效的利用珍貴的標注資料，幫助那些尚不容易取得文字的語言發展語音語言科技，以協助保存他們的語言。
% // 問題是，有些語音任務並不需要抽內容嗎？


\section{章節安排}

　　由於本論文是以剖析既有的語音離散表徵為主軸，因此就相關研究方面需要從各角度入手，單獨成一章節。接著我們會從單一的離散單元，以及將單元視為像文字的字符（character）並進行分詞演算法兩種對語音離散單元處理的層次分別成章進行分析，最後將這些表徵嘗試做在語音的任務上，以驗證其具有一定的語音表徵能力，且能保留語音學的特徵。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\chapter{背景知識}
\section{深層類神經網路（deep neural network）}

　　深層類神經網路（Deep neural network） 是麥氏（McCulloch）在 1943 年提出 \cite{mcculloch1943logical}，取法自生物神經連結的計算模型，旨在模擬生物神經系統的連結，以模仿生物的各項功能，進而透過機器學習的最佳化演算法，使得整個模型能夠藉由資料去貼合理想的函數，以達成應用或工程上所需要的各種任務。 。

    以發展此模型為主軸的心理學流派，在計算認知神經科學中被稱為「連結派（connectionism）」，其後因為該網路的彈性與平行化的能力，和諸如圖形處理器（graph processing unit，GPU）等硬體裝置能夠 最好的利用。 
    并能夠更 好的描述資料分佈、達到前所未有的效能 ，因此近年在電腦科學的機器學習領域中獲得重大進展，並因此現已成為人工智慧發展的主流。

    基於深層類神經網路的神經架構有 CNN、RNN、Transformer 等等，由於這些架構在語音與文字處理上都已經被廣泛使用，因此在下面分別介紹：

\subsection{卷積式（convolutional）類神經網路}

　　卷積式類神經網路一開始是在 cite 中提出，主要是鑑於影像中的局部性（locality），讓 NN 可以在。在語音中，因為語音訊號的資訊是被呈現在時間維度上，因此通常使用一維的卷積式類神經網路，以捕捉時間維度上的局部性特徵，例如本研究特別探討的 phoneme、morpheme 等等。

\subsection{遞迴式（recurrent）類神經網路}

\subsection{
    序列至序列（sequence-to-sequence）模型}
    
    由于許多實際上的資料都是2個序 之間互相配對的關系 此類的資料包含語音文字。 信號等等，都是以時間軸為主要 演變方向的資料。 因此 有一類模型。 會被以序列制序列的模式進行訓練。 旨在模擬輸入與輸出序列之間的變化與相依關係（dependency）。

此類模型一般的架構是由一個編碼器和解碼器構成 其中編碼器是將輸入訊號借由內部表征進行編碼。 依據每個時間點輸入訊號的順序來改變其內部表征的狀態 接著將最後一個時間點的表徵作為整個序列的特征傳遞給解碼器進行輸出訊號 生成。 
    
\subsection{專注（attention）機制}
    
    原本的序列自序列模型本身。 需要讓解碼器單純透過最後一個時間 點。 的表征資訊來完全儲存輸入序列的一切資訊 以工解碼器判斷。 并生成輸出序列。 然而，由于 單就最後一個向量進行判斷對於解碼器而言過於不易。因此。 盧氏提出。 在編碼器中對輸入序列的不同時間點進行注意力機制 亦即讓解碼器可以根據當下 所需要輸出的 內容判斷應該要重新對輸入序列的哪些部份 進行更多的加權 。

    

\subsection{轉換器（Transformer）}

其後，由瓦氏（Vaswani） cite 提出的 論文中 提出了一個完全由注意機制。 所構成的序列自序列模型。 原先該模型適用於解決機器翻譯。 的問題。
由於其能夠高度平行化的特性， 日後在 自然源處理和語音處理，甚至到電腦視覺領域等近乎整個深層學習的領域都被廣泛的應用。  


\section{表徵（representation）學習}

\subsection{文字的語意表徵}



\subsection{語音特徵與表徵}


\section{語音基石模型與自監督式學習}

\subsection{自監督式學習}

\subsection{語音基石模型}

\subsection{離散單元}


\section{本章總結}


