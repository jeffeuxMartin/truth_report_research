\chapter{結論與展望}

\section{研究貢獻與討論}
　　
本論文的主旨，在於分析語音基石模型的離散表徵，與語音標註之間的純度和相互資訊等數據的相關性，並且透過分詞方法的引入，嘗試將多個離散單元進行結合後，觀察學習到的新符記是否和音位等標註更加一致。 

首先，論文第三章介紹了與無文字架構以及語音表徵相關的分析研究，隨後簡介語音學知識中，對於不同音位之間如何按照發音特性分門別類。有了音位與語音學分類兩種語音標註後，借鑑 HuBERT 提及的純度和相互資訊的分析方式，對離散表徵與語音標註之間，兩者的相關性進行分析與觀察，比對無文字架構中不同語音離散表徵的統計特性。結果可發現，HuBERT 作為目前無文字架構最常用的語音離散表徵模型的理由，很可能來自於它們的音位純度與相互資訊都相對較高，因而更能捕捉到語音中與內容相關的重要資訊，且同樣的趨勢在語音學分類的標註也可以被觀察到。

其後在論文第四章，考慮到音位與離散單元往往是一對多的關係，
藉著嘗試引入自然語言處理常用的分詞方法，
重新對離散單元的序列進行分組，並且比較不同詞表大小對這些分析數據的影響。
考量語音不如英語的文字系統具備明確的空格提示，
本研究採取單一詞作為分詞方法進行
實驗，
並比較不同模型與不同詞表大小對第三章的分析數據是否造成影響。

結果顯示，
藉助加入分詞方法並提供足夠大的詞表，確實能夠讓不同音位的純度以及相互資訊有所提升，
讓多個離散單元之間有機會相互結合、重新分組，更能捕捉語音訊號中的內容資訊。
且在四種語音表徵之間，HuBERT 依然是所有模型中音位純度和相互資訊最高者，還達成了一定的序列長度壓縮比率，相較之下 CPC 模型雖然壓縮比率更低，卻犧牲掉過多語音資訊導致相關數據反而較差。這也解釋了為什麼目前在離散單元相關的研究中，無論是使用單一離散單元，或是使用分詞方法進行長度壓縮等，HuBERT 都仍是最有利於後續語音任務的訓練與應用的模型。

 

\section{未來展望}
　　
希望這些對離散單元與分詞方法應用的嘗試，能幫助我們在訓練任務之前，決定哪種語音基石模型更適合作為離散編碼語音訊號的基礎。接下來，我們期望能針對常見的語音任務，特別是語音辨識和語音翻譯等內容處理相關的任務，比對離散單元促成的實際成效和分析數據之間的關係，並對這些任務中的錯誤案例進行統計和個案探討。

另外，對於如何結合語音離散單元，除了將其視為文字進行分詞演算法外，我們還可以使用其他方式對離散單元序列進行分組，以達成壓縮序列長度並使其與音位等語音內容更加一致的目標。例如，將此目標形塑為語音分段（Speech Segmentation）任務等，也是未來可以嘗試的離散單元分組方式。

最後，利用語音學分組的切入點，或許可以在未來分析離散單元或連續語音表徵時，不再僅限於參考音位或文字，還可以從語音學知識提供的相似性資訊出發，為錯誤發音修正等任務提供衡量的依據。
