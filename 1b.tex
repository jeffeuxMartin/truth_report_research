
% 直接快速帶過連續的 Speech Repr
% Acoustic Piece 那邊的文獻到後面再寫。到這裡已經夠承先啟後了
    
\section{研究方向}
　　
本研究論文為了探究離散單元本身是否具有潛力可以單純透過大量語音資料的自監督學習與統計過程，從文本中找尋出語音中更精細的結構，乃至於類似文字或是從語言學（Linguistics）等人類知識領域定義出的「離散單位」 --- 如音素（Phone）、音位（Phoneme）、字符（Character）、「詞綴與字根」（即「詞素（Morpheme）」）或單字（Word）等等。因此，本研究取法自 HuBERT 本身為了證明其離散單元具有一定的「聲學單元（Acoustic Unit）」特性的「純度（Purity）」和「相互資訊（Mutual Information，MI）」的分析數據作為分析離散語音表徵和「音位」 --- 作為人類知識理解語音中最基礎的單位 --- 之間相關性（Correlation）的參考。

此外，基於訊號速率（如序列的長度）的考量，結合在文字處理中如 BPE 等等常見的次詞單位（Subword）分詞（Tokenization）演算法，基於形式上的相似性，因而也可以套用在像是 HuBERT離散單元這種離散的符號上，將離散單元序列中相似的規律（Pattern）發掘出來。近期如 Wav2Seq \cite{wu_wav2seq_2023}、\cite{ren_speech_2022}、\cite{chang_exploring_2024} 等作品也先進行了類似的嘗試。本論文則是在除了經驗上（Empirically）將其用於大量資料訓練的視角以外，從「將其視為另一種離散單位」的觀點進行統計數據的量化分析（Quantitative Analysis），作為在計算資源有限的前提下決策數據編碼的一個判斷標準。

\section{主要貢獻}
　　
本論文達成的主要成果是以更細緻的方式，對現在愈來愈廣為使用的離散單元以音位和語音類別等語音知識的視角給出一個基礎相關性的分析方法，並將單一離散單元本身與將多個單元透過分詞演算法（Tokenization）重新編碼前後進行比較，初步試探離散單元與音位之間的關係，並期望作為「離散單元 可否一定程度上的『被視為文字』或『有機會從中發掘出文字單位』」的判斷基礎，為往後研究往語音語言模型（Spoken Language Model）中「對語音編碼」這個重要的程序，提供一個在實際上開始耗費資源的模型訓練之前，可比較的判斷標準。

\section{章節安排}

本論文將以如下的方式進行章節安排：

\begin{itemize}
  \itemsep -2pt %reduce Space Between Items
  \item  第二章：介紹後面章節所需要的與深層學習（Deep Learning）、表徵學習與自監督學習相關的基礎背景知識。
  \item  第三章：從介紹離散單元本身提出後，「無文字」的相關前作文獻開始，帶出對從無文字系列作品用到的各種自監督學習模型抽取之離散單元本身的純度（Purity）和相互資訊（Mutual Information，MI）等統計數據，進行比較與分析。
  \item  第四章：講述為何單一離散單元本身或許不全然足夠發掘出類似音位進而對應到文字的單位，以及近年人們嘗試以離散單元為基礎，透過分詞演算法（Tokenization Algorithm）發展之聲學片段（Acoustic Piece） 的進展，接著我們將單元進行分詞法重新編碼處理前後，觀察數據上與第三章結果間的差異，以論證對離散單元進行分詞是否可以找出更接近音位的單位，驗證「離散單元可被文字化」或「離散單元學到的是否為更精細的語音訊號規律或結構（Structure）」等論述。
  \item  第五章：總結前面的觀察結果，並進一步探討本研究還可以如何延伸，並怎麼幫助語音語言模型的發展。
\end{itemize}
