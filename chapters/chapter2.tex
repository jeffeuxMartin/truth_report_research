% !TeX root = ../thesis.tex

% ============================================================ %
% ============================================================ %

\chapter{背景知識}

由於本論文用到的 units 來自自監督學習的語音表徵，因此在介紹主要研究內容之前，我們會先介紹自監督學習 

\section{深層類神經網路（deep neural network）}

　　
深層類神經網路（Deep neural network）是來自於神經心理學家麥氏（McCulloch）等人在 1943 年提出 \cite{mcculloch1943logical}，取法自生物神經連結的計算模型。以發展此類模型為主軸的心理學流派，在計算認知神經科學中被稱為「連結派（connectionism）」，旨在模擬生物神經系統的連結，以模仿生物的各項功能。爾後在工程界進而透過機器學習的最佳化演算法，使得整個模型能夠藉由資料去貼合（fit）理想的函數，以達成應用或工程上所需要的各種任務。因為該類網路的彈性與計算上易於平行化的特徵，能夠很恰當的利用諸如圖形處理器（graphics processing unit，GPU）等硬體裝置的優勢，以求更好的描述資料分佈、達到前所未有的效能，因此近年在電腦科學的機器學習領域中獲得重大進展，現已成為人工智慧發展的主流。

% 基於深層類神經網路的神經架構有卷積式（convolutional）類神經網路（CNN）、遞迴式（recurrent）類神經網路（RNN）、轉換器類神經網路（Transformer）等等，由於這些架構在語音與文字處理上都已經被廣泛使用，因此在下面分別介紹：考慮要不要放上訓練過程？on 前面 NN


\subsection{簡介}

\subsection{訓練方式}

\subsection{前饋式類神經網路}　　
基於深層類神經網路的神經架構有 CNN、RNN、Transformer 等等，由於這些架構在語音與文字處理上都已經被廣泛使用，因此在下面分別介紹：

\subsection{卷積式（convolutional）類神經網路}　　
卷積式類神經網路（convolutional neural network）為 1998 年由楊氏（LeCun）提出 \cite{726791}，旨在利用訊號處理上卷積（convolution）的運算模擬人類視覺皮質感知 \cite{hubel1959receptive} 的特性，利用其移動不變性（shift-invariance）來捕捉二維影像中的局部（local）特徵，以便於後續的類神經網路可以對輸入的資料進行更整體而全面的判斷。



% 這邊是不是要處理不同 features
在語音處理的領域中，有別於影像的二維資料，語音訊號的資訊是被呈現在時間軸的維度上，因此通常使用一維的卷積式類神經網路，以模仿人耳聽覺對時變訊號的窗框（window）處理過程，讓模型可以觀察到輸入語音在不同解析度（resolution）上的資訊，例如本研究特別著重的音位（phoneme）等。


\subsection{遞迴式（recurrent）類神經網路}　　

\subsection{序列至序列（sequence-to-sequence）模型}　　
由於許多語言相關的資料都是兩個序列之間互相配對的關係，包含語音和文字等時序訊號等等，都是以時間軸為主要資料呈現的維度。因此這類資料通常會使用序列至序列的模式進行訓練，旨在模擬輸入與輸出序列之間的變化與相依關係（dependency）。

此類模型一般的架構是由一個編碼器（encoder）和一個解碼器（decoder）構成，其中編碼器是將輸入訊號藉由內部表徵（latent representation）進行編碼，依據每個時間點輸入訊號的變化來調整其內部表徵狀態，接著將最後一個時間點的表徵作為整個序列的代表，傳遞給解碼器生成輸出訊號的序列。該過程可由以下數學式表示：

$$\mathcal{L} _{ST}(\hat{\bm{y}}, \bm{y}) = -\sum_{t=1}^T \sum_{i=1}^V P_{\hat{y}_t}(\hat{y}_t = v_i)\log P_{y_t}(y_t = v_i) $$

\subsection{專注（attention）機制}　　
原本的序列自序列模型本身。 需要讓解碼器單純透過最後一個時間 點。 的表征資訊來完全儲存輸入序列的一切資訊 以工解碼器判斷。 并生成輸出序列。 然而，由于 單就最後一個向量進行判斷對於解碼器而言過於不易。因此。 盧氏提出。 在編碼器中對輸入序列的不同時間點進行注意力機制 亦即讓解碼器可以根據當下 所需要輸出的 內容判斷應該要重新對輸入序列的哪些部份 進行更多的加權 。

\subsection{轉換器（Transformer）}

其後，由瓦氏（Vaswani） cite 提出的 論文中 提出了一個完全由注意機制。 所構成的序列自序列模型。 原先該模型適用於解決機器翻譯。 的問題。
由於其能夠高度平行化的特性， 日後在 自然源處理和語音處理，甚至到電腦視覺領域等近乎整個深層學習的領域都被廣泛的應用。  

\section{表徵（representation）學習與自監督式學習（SSL）}

\subsection{特徵}

原本在文字和語音。文字會用 TF-IDF 等等，語音則會用 mel 和 MFCC

\subsection{表徵學習}

後來基於 Mikolov 的 Word2Vec
word2vec 是 mikolov \CITEME 最早提出跟對於文字進行語義表徵的 work。在其後
開始嘗試從大量資料去學習出表徵

結合 contextulaized embedding 有了 ELMo

\subsection{自監督學習（self-supervised learning，SSL） (這邊接下來直接看以前碩論怎麼分。宏毅的再說）}

從 contextulaized 的精神，結合 SAttn，BERT 被提出來，並有了 SSL 的概念

SSL 的好處是可以更好的利用 NN 的學習與泛化（generalization）能力，從大量的未標註資料中，就由 pretext tasks 的引導，在 unsupervised 的情形下利用資料本身結構進行學習。

（提到「提出了很多語音基石模型」）

\subsubsection{重建式學習}

BERT
以重建被
遮罩語言模型

\subsubsection{預測式學習}

GPT
APC


\subsubsection{對比式學習}

CPC // 所以這個在後面會不會出事？

\subsection{向量量化（vector quantization）}



\subsection{離散單元}



\section{本章總結}


