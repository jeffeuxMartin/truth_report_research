% !TeX root = ../thesis.tex

% ============================================================ %
% ============================================================ %

\chapter{
背景知識}
由於本論文用到的 units 來自自監督學習的語音表徵，因此在介紹主要研究內容之前，我們會先介紹自監督學習 
\section{深層類神經網路（deep neural network）}

　　深層類神經網路（Deep neural network） 是麥氏（McCulloch）在 1943 年提出 \cite{mcculloch1943logical}，取法自生物神經連結的計算模型，旨在模擬生物神經系統的連結，以模仿生物的各項功能，進而透過機器學習的最佳化演算法，使得整個模型能夠藉由資料去貼合理想的函數，以達成應用或工程上所需要的各種任務。 。

    以發展此模型為主軸的心理學流派，在計算認知神經科學中被稱為「連結派（connectionism）」，其後因為該網路的彈性與平行化的能力，和諸如圖形處理器（graph processing unit，GPU）等硬體裝置能夠 最好的利用。 
    并能夠更 好的描述資料分佈、達到前所未有的效能 ，因此近年在電腦科學的機器學習領域中獲得重大進展，並因此現已成為人工智慧發展的主流。

\subsection{簡介}
\subsection{訓練方式}

\subsection{FFN}

    基於深層類神經網路的神經架構有 CNN、RNN、Transformer 等等，由於這些架構在語音與文字處理上都已經被廣泛使用，因此在下面分別介紹：

\subsection{卷積式（convolutional）類神經網路}

　　卷積式類神經網路一開始是在 cite 中提出，主要是鑑於影像中的局部性（locality），讓 NN 可以在。在語音中，因為語音訊號的資訊是被呈現在時間維度上，因此通常使用一維的卷積式類神經網路，以捕捉時間維度上的局部性特徵，例如本研究特別探討的 phoneme、morpheme 等等。

\subsection{遞迴式（recurrent）類神經網路}

\subsection{
    序列至序列（sequence-to-sequence）模型}
    
    由于許多實際上的資料都是2個序 之間互相配對的關系 此類的資料包含語音文字。 信號等等，都是以時間軸為主要 演變方向的資料。 因此 有一類模型。 會被以序列制序列的模式進行訓練。 旨在模擬輸入與輸出序列之間的變化與相依關係（dependency）。

此類模型一般的架構是由一個編碼器和解碼器構成 其中編碼器是將輸入訊號借由內部表征進行編碼。 依據每個時間點輸入訊號的順序來改變其內部表征的狀態 接著將最後一個時間點的表徵作為整個序列的特征傳遞給解碼器進行輸出訊號 生成。 
    
\subsection{專注（attention）機制}
    
    原本的序列自序列模型本身。 需要讓解碼器單純透過最後一個時間 點。 的表征資訊來完全儲存輸入序列的一切資訊 以工解碼器判斷。 并生成輸出序列。 然而，由于 單就最後一個向量進行判斷對於解碼器而言過於不易。因此。 盧氏提出。 在編碼器中對輸入序列的不同時間點進行注意力機制 亦即讓解碼器可以根據當下 所需要輸出的 內容判斷應該要重新對輸入序列的哪些部份 進行更多的加權 。

    

\subsection{轉換器（Transformer）}

其後，由瓦氏（Vaswani） cite 提出的 論文中 提出了一個完全由注意機制。 所構成的序列自序列模型。 原先該模型適用於解決機器翻譯。 的問題。
由於其能夠高度平行化的特性， 日後在 自然源處理和語音處理，甚至到電腦視覺領域等近乎整個深層學習的領域都被廣泛的應用。  


\section{表徵（representation）學習與自監督式學習（SSL）}


\subsection{特徵}

原本在文字和語音。文字會用 TF-IDF 等等，語音則會用 mel 和 MFCC

\subsection{表徵學習}

後來基於 Mikolov 的 Word2Vec
word2vec 是 mikolov \CITEME 最早提出跟對於文字進行語義表徵的 work。在其後
開始嘗試從大量資料去學習出表徵

結合 contextulaized embedding 有了 ELMo

\subsection{SSL (這邊接下來直接看以前碩論怎麼分。宏毅的再說）}

從 contextulaized 的精神，結合 SAttn，BERT 被提出來，並有了 SSL 的概念

SSL 的好處是可以更好的利用 NN 的學習與泛化（generalization）能力，從大量的未標註資料中，就由 pretext tasks 的引導，在 unsupervised 的情形下利用資料本身結構進行學習。

\subsubsection{MLM/recon}

BERT

\subsubsection{CLM/predictive}

GPT, APC

\subsubsection{contrastive}

CPC // 所以這個在後面會不會出事？

 




\section{語音基石模型與自監督式學習}

\subsection{自監督式學習}

\subsection{語音基石模型}

\subsection{離散單元}


\section{本章總結}


