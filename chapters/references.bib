
@misc{noauthor_textless_nodate,
	title = {Textless {NLP}: {Generating} expressive speech from raw audio},
	shorttitle = {Textless {NLP}},
	url = {https://ai.meta.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/},
	abstract = {We’re introducing GSLM, the first language model that breaks free completely of the dependence on text for training. This “textless NLP” approach learns to generate expressive speech using only raw audio recordings as input.},
	language = {en},
	urldate = {2024-05-25},
}

@misc{lakhotia_generative_2021,
	title = {Generative {Spoken} {Language} {Modeling} from {Raw} {Audio}},
	url = {http://arxiv.org/abs/2102.01192},
	doi = {10.48550/arXiv.2102.01192},
	abstract = {We introduce Generative Spoken Language Modeling, the task of learning the acoustic and linguistic characteristics of a language from raw audio (no text, no labels), and a set of metrics to automatically evaluate the learned representations at acoustic and linguistic levels for both encoding and generation. We set up baseline systems consisting of a discrete speech encoder (returning pseudo-text units), a generative language model (trained on pseudo-text), and a speech decoder (generating a waveform from pseudo-text) all trained without supervision and validate the proposed metrics with human evaluation. Across 3 speech encoders (CPC, wav2vec 2.0, HuBERT), we find that the number of discrete units (50, 100, or 200) matters in a task-dependent and encoder-dependent way, and that some combinations approach text-based systems.},
	urldate = {2024-05-25},
	publisher = {arXiv},
	author = {Lakhotia, Kushal and Kharitonov, Evgeny and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Adelrahman and Dupoux, Emmanuel},
	month = sep,
	year = {2021},
	note = {arXiv:2102.01192 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{rosenblatt_perceptron_1958,
	title = {The perceptron: a probabilistic model for information storage and organization in the brain.},
	volume = {65},
	number = {6},
	journal = {Psychological review},
	author = {Rosenblatt, Frank},
	year = {1958},
	note = {Publisher: American Psychological Association},
	pages = {386},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	doi = {10.1109/5.726791},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	year = {1998},
	keywords = {Character recognition, Feature extraction, Hidden Markov models, Machine learning, Multi-layer neural network, Neural networks, Optical character recognition software, Optical computing, Pattern recognition, Principal component analysis},
	pages = {2278--2324},
}

@inproceedings{hsu_hubert_2021,
	title = {{HuBERT}: {How} much can a bad teacher benefit {ASR} pre-training?},
	booktitle = {{ICASSP} 2021-2021 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Hsu, Wei-Ning and Tsai, Yao-Hung Hubert and Bolte, Benjamin and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
	year = {2021},
	pages = {6533--6537},
}

@inproceedings{zhao_speech_2023,
	title = {Speech {Enhancement} with {Multi}-granularity {Vector} {Quantization}},
	booktitle = {2023 {Asia} {Pacific} {Signal} and {Information} {Processing} {Association} {Annual} {Summit} and {Conference} ({APSIPA} {ASC})},
	publisher = {IEEE},
	author = {Zhao, Xiaoying and Zhu, Qiushi and Zhang, Jie and Zhou, Yeping and Liu, Peiqi},
	year = {2023},
	pages = {1937--1942},
}

@inproceedings{wu_wav2seq_2023,
	title = {Wav2seq: {Pre}-training speech-to-text encoder-decoder models using pseudo languages},
	booktitle = {{ICASSP} 2023-2023 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Wu, Felix and Kim, Kwangyoun and Watanabe, Shinji and Han, Kyu J and McDonald, Ryan and Weinberger, Kilian Q and Artzi, Yoav},
	year = {2023},
	pages = {1--5},
}

@misc{oord_representation_2019,
	title = {Representation {Learning} with {Contrastive} {Predictive} {Coding}},
	author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	year = {2019},
	note = {\_eprint: 1807.03748},
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	journal = {The bulletin of mathematical biophysics},
	author = {McCulloch, Warren S and Pitts, Walter},
	year = {1943},
	note = {Publisher: Springer},
	pages = {115--133},
}

@inproceedings{lee_self-supervised_2022,
	title = {Self-supervised representation learning for speech processing},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}: {Tutorial} {Abstracts}},
	author = {Lee, Hung-yi and Mohamed, Abdelrahman and Watanabe, Shinji and Sainath, Tara and Livescu, Karen and Li, Shang-Wen and Yang, Shu-wen and Kirchhoff, Katrin},
	year = {2022},
	pages = {8--13},
}

@article{lakhotia_generative_2021-1,
	title = {On generative spoken language modeling from raw audio},
	volume = {9},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and {others}},
	year = {2021},
	note = {Publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {1336--1354},
}

@article{hubel_receptive_1959,
	title = {Receptive fields of single neurones in the cat's striate cortex},
	volume = {148},
	number = {3},
	journal = {The Journal of physiology},
	author = {Hubel, David H and Wiesel, Torsten N},
	year = {1959},
	note = {Publisher: Wiley-Blackwell},
	pages = {574},
}

@article{chang_exploration_nodate,
	title = {Exploration of {Efficient} {End}-to-{End} {ASR} using {Discretized} {Input} from {Self}-{Supervised} {Learning}},
	author = {Chang, Xuankai and Yan, Brian and Fujita, Yuya and Maekaku, Takashi and Watanabe, Shinji},
}

@inproceedings{chang_exploring_2024,
	title = {Exploring speech recognition, translation, and understanding with discrete speech units: {A} comparative study},
	booktitle = {{ICASSP} 2024-2024 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Chang, Xuankai and Yan, Brian and Choi, Kwanghee and Jung, Jee-Weon and Lu, Yichen and Maiti, Soumi and Sharma, Roshan and Shi, Jiatong and Tian, Jinchuan and Watanabe, Shinji and {others}},
	year = {2024},
	pages = {11481--11485},
}

@inproceedings{ren_speech_2022,
	title = {Speech {Pre}-training with {Acoustic} {Piece}},
	url = {https://doi.org/10.21437/Interspeech.2022-981},
	doi = {10.21437/INTERSPEECH.2022-981},
	booktitle = {Interspeech 2022, 23rd {Annual} {Conference} of the {International} {Speech} {Communication} {Association}, {Incheon}, {Korea}, 18-22 {September} 2022},
	publisher = {ISCA},
	author = {Ren, Shuo and Liu, Shujie and Wu, Yu and Zhou, Long and Wei, Furu},
	editor = {Ko, Hanseok and Hansen, John H. L.},
	year = {2022},
	pages = {2648--2652},
}

@inproceedings{chen_speech--speech_2023,
	title = {Speech-to-{Speech} {Translation} for a {Real}-world {Unwritten} {Language}},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2023},
	author = {Chen, Peng-Jen and Tran, Kevin and Yang, Yilin and Du, Jingfei and Kao, Justine and Chung, Yu-An and Tomasello, Paden and Duquenne, Paul-Ambroise and Schwenk, Holger and Gong, Hongyu and {others}},
	year = {2023},
	pages = {4969--4983},
}

@book{eberhard_ethnologue_2024,
	address = {Dallas, Texas},
	edition = {27th},
	title = {Ethnologue: {Languages} of the {World}},
	url = {https://www.ethnologue.com},
	publisher = {SIL International},
	author = {Eberhard, David M. and Simons, Gary F. and Fennig, Charles D.},
	year = {2024},
}

@article{chorowski_unsupervised_2019,
	title = {Unsupervised speech representation learning using wavenet autoencoders},
	volume = {27},
	number = {12},
	journal = {IEEE/ACM transactions on audio, speech, and language processing},
	author = {Chorowski, Jan and Weiss, Ron J and Bengio, Samy and Van Den Oord, Aäron},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {2041--2053},
}

@inproceedings{chen_vector_2023,
	title = {A vector quantized approach for text to speech synthesis on real-world spontaneous speech},
	volume = {37},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Chen, Li-Wei and Watanabe, Shinji and Rudnicky, Alexander},
	year = {2023},
	note = {Issue: 11},
	pages = {12644--12652},
}

@article{baevski_wav2vec_2020,
	title = {wav2vec 2.0: {A} framework for self-supervised learning of speech representations},
	volume = {33},
	journal = {Advances in neural information processing systems},
	author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
	year = {2020},
	pages = {12449--12460},
}
