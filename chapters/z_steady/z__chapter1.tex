% !TeX root = ../../thesis.tex
\chapter{導論}
\section{研究動機}
　　
語言是人與人彼此交流最主要的橋樑，而人們互相溝通最自然的方式便是透過說話的語音（speech）達成。人類往往是自幼就牙牙學語開始說話，直到已屆學齡左右才開始學習認字與書寫。雖然在這個資訊爆炸的時代，人們已經習慣以文字呈現的語言作為獲取資訊的主要媒介，但不論如何，各種書寫系統其背後承載的語言必定有語音的形式作為對應。更何況世界上現存大約七千多種  \cite{ethnologue}  語言中，絕大多數不見得存在成熟且普及的文字系統，卻無礙於這些語言被人們所熟悉和使用。因此，「語音」作為語言不可或缺的存在方式，了解它和研究它的價值自然不言而喻。

然而，相對於穩定、易於處理和保存的文字文本，語音訊號的變化萬千，蘊藏了大量從語者風格、表達內容到抑揚頓挫（韻律，prosody）等不同層次的訊息，使得對它的處理、研究相比之下複雜度與難度劇增。由於語音的這種特性，過往對於語言最有興趣的語言學家們，即便明白語音作為多數語言主體的事實，也不得不藉文字符號為依託進行探索。進入資訊化時代後，藉助電腦硬體等計算設備的幫助，從語料庫、計算語言學到自然語言處理等透過科技的力量發展語言處理技術的領域，頗長一段時間也是專注於文字的處理與分析。
而嘗試結合訊號處理發展的語音技術領域，當時則是透過語言學家對語言的領域知識，例如從音位（phoneme）、構詞（morphology）、語法（syntax）等等用以刻劃人類語音和語言特性的概念，將之結合機器學習建立模型，開發技術以方便人們能以語音這種更靈活的媒介，更好的讓電腦、手機等科技工具可以更接近「直接溝通」的使用方式，便利人們的日常生活。

近年來，由於圖形處理器（graphics processing unit，GPU）等硬體平行運算技術的進步，深層學習（deep learning）快速崛起成為人工智慧的主流，有了此項機器學習的技術，模型的彈性能夠更好的萃取資料、更貼近的尋找資料背後的機制並進行預測，使得人們不再非得依賴大量費時費工的人類標注過程，進而使得利用大量語料庫發展語言技術，進一步推進語言科技發展成為可能。尤其在自監督學習（self-supervised learning）技術出現之後，深層學習模型可以依照人們給定的方向，更細緻的從大量未標注、相較容易取得的語音或文字的語料，找出其中的語音、語法及語義等等結構，形成帶有對人類語言有前所未見表現的基石模型（foundation model），是這個領域的一大里程碑。尤其在以處理文字為主體的自然語言處理領域，甚至出現了幾乎使人類真偽難辨的生成式模型，改變了人們生活的方方面面。

借鏡文字方面的成功經驗，語音處理領域的研究者們也開始嘗試將語言模型（language model）的概念套用於變化莫測的語音訊號之上，原先人們藉助訊號處理知識一直使用的各種語音訊號特徵（feature）也在自監督學習的架構之下，出現了許多模型從大量語音資料中得到的「語音表徵（speech representation）」，作為精煉語音資訊的另外一種新選擇開始廣泛被採用。然而，相比於文字符號的穩定與單純，語音的複雜性使得它處理起來會需要更大量的資料和運算資源來擷取其中不同層次的細節，而且作為物理訊號，語音還必須處理掉環境中的雜訊等干擾。為了從紛亂的聲音中提取出最重要的訊息，向量量化（vector quantization）的技巧因而經常被使用在語音 \cite{chorowski2019unsupervised, chen2023vector, zhao2023speech} 或影像的領域中。爾後， \cite{lakhotia2021generative}  基於模仿人類學習語言的過程，藉助諸如 CPC（\cite{oord2019representation} ）、HuBERT （\cite{hsu2021hubert} ）、wav2vec 2.0 （\cite{baevski2020wav2vec} ）等自監督學習模型的幫助，引入向量量化的技術，提出了「無文字（textless）」的學習架構，轉而以語音表徵量化後的「離散單元（discrete unit）」作為操作對象，企圖以單純大量的語音資料中訓練出一個不依賴文字的語言模型。此種學習架構的優勢在於在能保有利用大量未標注文字轉寫語音資料的同時，與連續表徵相比資訊的位元率（bit rate）利用更有效率、容易儲存、處理與傳輸，以及形式上更像文字的特性，因而可以將其視為一種「機器自己學習出來的文字」，接下來借用長久以來只能在自然語言處理（natural language processing，NLP）領域中各種語言模型（language model）的相關技術和任務的解決方法，套用在語音處理的領域中，期望可以像文字那樣從大量的語音資料中，找尋出「語音訊號版本的文字」。自此之後有一系列如應用於英語和閩南語之間的語音到語音翻譯 \cite{chen2023speech} 等等使用離散單元（discrete unit）進行任務訓練的研究，一定程度的印證了這些離散單元捕捉語音內容的效果。

儘管離散單元在編碼語音之上固然有不錯的效果，並有相關研究展現了離散單元具有一定程度上與文字的相似性，然而其作為「完全文字的替代」仍然有相當的距離。借鑑過往在自監督學習的語音表徵出來之後，便嘗試重新從語言學（linguistics）的概念汲取靈感，對其進行語音學（phonetics）層面的分析。本論文期望初步結合原先 HuBERT 中從消息理論（information theory）的統計數據，結合語音學分析的視角，對於離散表徵（discrete representation）本身與音位（phoneme）和語音類別（phone type）之間的關係進行相關性的統計與分析，期望可以對 HuBERT 等自監督學習表徵進行量化（quantization）後所得的離散單元所編碼、擷取到的資訊是什麼有較為深入程度的了解。

% 直接快速帶過連續的 speech repr
% acoustic piece 那邊的文獻到後面再寫。到這裡已經夠承先啟後了
    
\section{研究方向}
　　
本研究論文為了探究離散單元本身是否具有潛力可以單純透過大量語音資料的自監督學習與統計過程，從文本中找尋出語音中更精細的結構，乃至於類似文字或是從語言學（linguistics）等人類知識領域定義出的「離散單位」－－如音素（phone）、音位（phoneme）、字符（character）、「詞綴與字根」（即「詞素（morpheme）」）或單字（word）等等。因此，本研究取法自 HuBERT 本身為了證明其離散單元具有一定的「聲學單元（acoustic unit）」特性的「純度（purity）」和「相互資訊（mutual information，MI）」的分析數據作為分析離散語音表徵和「音位」－－作為人類知識理解語音中最基礎的單位－－之間相關性（correlation）的參考。

此外，基於訊號速率（如序列的長度）的考量，結合在文字處理中如 BPE 等等常見的次詞單位（subword）分詞（tokenization）演算法，基於形式上的相似性，因而也可以套用在像是 HuBERT離散單元這種離散的符號上，將離散單元序列中相似的規律（pattern）發掘出來。近期如 Wav2Seq \cite{wu2023wav2seq}、\cite{DBLP:conf/interspeech/Ren00ZW22}、\cite{chang2024exploring} 等作品也先進行了類似的嘗試。本論文則是在除了經驗上（empirically）將其用於大量資料訓練的視角以外，從「將其視為另一種離散單位」的觀點進行統計數據的量化分析（quantitative analysis），作為在計算資源有限的前提下決策數據編碼的一個判斷標準。

\section{主要貢獻}
　　
本論文達成的主要成果是以更細緻的方式，對現在愈來愈廣為使用的離散單元以音位和語音類別等語音知識的視角給出一個基礎相關性的分析方法，並將單一離散單元本身與將多個單元透過分詞演算法（tokenization）重新編碼前後進行比較，初步試探離散單元與音位之間的關係，並期望作為「離散單元 可否一定程度上的『被視為文字』或『有機會從中發掘出文字單位』」的判斷基礎，為往後研究往語音語言模型（spoken language model）中「對語音編碼」這個重要的程序，提供一個在實際上開始耗費資源的模型訓練之前，可比較的判斷標準。

\section{章節安排}

本論文將以如下的方式進行章節安排：

\begin{itemize}
  \itemsep -2pt %reduce space between items
  \item  第二章：介紹後面章節所需要的與深層學習（deep learning）、表徵學習與自監督學習相關的基礎背景知識。
  \item  第三章：從介紹離散單元本身提出後，「無文字」的相關前作文獻開始，帶出對從無文字系列作品用到的各種自監督學習模型抽取之離散單元本身的純度（purity）和相互資訊（mutual information，MI）等統計數據，進行比較與分析。
  \item  第四章：講述為何單一離散單元本身或許不全然足夠發掘出類似音位進而對應到文字的單位，以及近年人們嘗試以離散單元為基礎，透過分詞演算法（tokenization algorithm）發展之聲學片段（acoustic piece） 的進展，接著我們將單元進行分詞法重新編碼處理前後，觀察數據上與第三章結果間的差異，以論證對離散單元進行分詞是否可以找出更接近音位的單位，驗證「離散單元可被文字化」或「離散單元學到的是否為更精細的語音訊號規律或結構（structure）」等論述。
  \item  第五章：總結前面的觀察結果，並進一步探討本研究還可以如何延伸，並怎麼幫助語音語言模型的發展。
\end{itemize}
